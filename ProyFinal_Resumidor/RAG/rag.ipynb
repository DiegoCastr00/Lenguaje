{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip -q install langchain huggingface_hub tiktoken\n",
    "# %pip -q install chromadb\n",
    "# %pip -q install PyPDF2 pypdf sentence_transformers\n",
    "# %pip -q install --upgrade together\n",
    "# %pip -q install -U FlagEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
      "\n",
      "If the question is not directly related to the provided context, politely inform the user that the question is outside the context scope and cannot be answered accurately.\n",
      "\n",
      "Ensure that your answers are clear and concise, avoiding ambiguity or vague responses.\n",
      "<</SYS>>\n",
      "\n",
      "CONTEXT:/n/n {context}/n\n",
      "\n",
      "Question: {question}[/INST]\n"
     ]
    }
   ],
   "source": [
    "def create_embeddings(pdf):\n",
    "    pdf_reader = PdfReader(pdf)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "        )        \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    print(\"Number of chunks:\", len(chunks))\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "    knowledge_base = FAISS.from_texts(chunks, embeddings)\n",
    "    print(\"BD creada\")\n",
    "    return knowledge_base\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "sys_prompt = \"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
    "\n",
    "If the question is not directly related to the provided context, politely inform the user that the question is outside the context scope and cannot be answered accurately.\n",
    "\n",
    "Ensure that your answers are clear and concise, avoiding ambiguity or vague responses.\"\"\"\n",
    "\n",
    "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "prompt_template = get_prompt(instruction, sys_prompt)\n",
    "\n",
    "print(prompt_template)\n",
    "llama_prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": llama_prompt}\n",
    "\n",
    "import textwrap\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "\n",
    "def modelo_llm(modelo):\n",
    "    return TogetherLLM(\n",
    "        model= modelo,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import together\n",
    "from typing import Any\n",
    "from langchain.llms.base import LLM\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"f8935229473a0d8a3f4709a9ef32533fe365c0cb215ba8c41413b5ca53a5c767\"\n",
    "\n",
    "class TogetherLLM(LLM):\n",
    "    model: str = \"togethercomputer/llama-2-7b-chat\"\n",
    "    together_api_key: str = os.environ[\"TOGETHER_API_KEY\"]\n",
    "    temperature: float = 0.1\n",
    "    max_tokens: int = 1024\n",
    "    class Config:\n",
    "        extra = 'forbid'\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"together\"\n",
    "    def _call(self, prompt: str, **kwargs: Any) -> str:\n",
    "        if not self.together_api_key:\n",
    "            raise ValueError(\"API key is not set.\")\n",
    "        together.api_key = self.together_api_key\n",
    "        output = together.Complete.create(prompt,\n",
    "                                          model=self.model,\n",
    "                                          max_tokens=self.max_tokens,\n",
    "                                          temperature=self.temperature)\n",
    "        print(f\"modelo: {self.model}\")\n",
    "        if 'choices' in output:\n",
    "            return output['choices'][0]['text']\n",
    "        else:\n",
    "            raise KeyError(\"The key 'choices' is not in the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 98\n",
      "BD creada\n"
     ]
    }
   ],
   "source": [
    "pdf_obj = \"./prueba.pdf\"\n",
    "knowledge_base = create_embeddings(pdf_obj)\n",
    "retriever = knowledge_base.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18699/4062363579.py:26: DeprecationWarning: Call to deprecated function create.\n",
      "  output = together.Complete.create(prompt,\n",
      "/home/dante/.local/lib/python3.10/site-packages/together/legacy/complete.py:23: UserWarning: The use of together.api_key is deprecated and will be removed in the next major release. Please set the TOGETHER_API_KEY environment variable instead.\n",
      "  warnings.warn(API_KEY_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo: togethercomputer/llama-2-70b-chat\n",
      "  The related research found that incorporating local feature view clustering for 3D object recognition can\n",
      "easily incorporate other useful properties, such as color, motion, figure-ground discrimination, region shape\n",
      "descriptors, and stereo depth cues. Additionally, the use of multidimensional histograms summarizing the\n",
      "distribution of measurements within image regions may be particularly useful for recognition of textured\n",
      "objects with deformable shapes. The local feature approach can also easily incorporate better approaches, such\n",
      "as the model of biological vision proposed by Edelman, Intrator, and Poggio (1997), which allows for matching\n",
      "and recognition of 3D objects from a range of viewpoints.\n"
     ]
    }
   ],
   "source": [
    "modelo = \"togethercomputer/llama-2-70b-chat\"\n",
    "llm = modelo_llm(modelo)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                    chain_type=\"stuff\",\n",
    "                                    retriever=retriever,\n",
    "                                    chain_type_kwargs=chain_type_kwargs,)\n",
    "    \n",
    "query = \"What was found with the related research?\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "process_llm_response(llm_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
