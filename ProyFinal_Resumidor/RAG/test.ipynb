{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import together\n",
    "from typing import Any\n",
    "from langchain.llms.base import LLM\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NO TOCAR!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOGETHER_API_KEY\"] = \"f8935229473a0d8a3f4709a9ef32533fe365c0cb215ba8c41413b5ca53a5c767\"\n",
    "\n",
    "class TogetherLLM(LLM):\n",
    "    model: str = \"togethercomputer/llama-2-7b-chat\"\n",
    "    temperature: float = 0.1\n",
    "    max_tokens: int = 1024\n",
    "    together_api_key: str = os.environ.get(\"TOGETHER_API_KEY\")\n",
    "    \n",
    "    class Config:\n",
    "        extra = 'forbid'\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"together\"\n",
    "    def _call(self, prompt: str, **kwargs: Any) -> str:\n",
    "        if not self.together_api_key:\n",
    "            raise ValueError(\"API key is not set.\")\n",
    "        together.api_key = self.together_api_key\n",
    "        output = together.Complete.create(prompt,\n",
    "                                        model=self.model,\n",
    "                                        max_tokens=self.max_tokens,\n",
    "                                        temperature=self.temperature)\n",
    "        print(f\"modelo: {self.model}\")\n",
    "        if 'choices' in output:\n",
    "            return output['choices'][0]['text']\n",
    "        else:\n",
    "            raise KeyError(\"The key 'choices' is not in the response.\")\n",
    "\n",
    "# Funcion para traduccion a ingles\n",
    "from googletrans import Translator\n",
    "import googletrans\n",
    "translator = Translator()\n",
    "\n",
    "def traducir(texto_original):\n",
    "    try :\n",
    "        origen = translator.detect(texto_original).lang\n",
    "        # Si el texto esta en otro idioma que no sea ingles lo traduce\n",
    "        if origen != \"en\":\n",
    "            #print(f'Traduccion de {origen} a en')\n",
    "            traduccion = translator.translate(texto_original, dest=\"en\", src=origen).text\n",
    "            return traduccion\n",
    "        # En caso contrario devuelve el texto original ya que esta en ingles\n",
    "        else:\n",
    "            return texto_original\n",
    "    except:\n",
    "        return texto_original\n",
    "    \n",
    "# Funcion para traduccion a otro idioma\n",
    "def traducir_ingles(texto_ingles, idioma_destino):\n",
    "    for abreviatura, nombre_idioma in googletrans.LANGUAGES.items():\n",
    "        if nombre_idioma == idioma_destino:\n",
    "            destino = abreviatura\n",
    "    traduccion = translator.translate(texto_ingles, dest=destino, src=\"en\").text\n",
    "    return traduccion\n",
    "\n",
    "def dividir_texto(texto, max_caracteres):\n",
    "    textos_divididos = []\n",
    "    texto_actual = ''\n",
    "    caracteres_actuales = 0\n",
    "\n",
    "    oraciones = texto.split('.')\n",
    "\n",
    "    for oracion in oraciones:\n",
    "        caracteres_actuales += len(oracion) + 1\n",
    "\n",
    "        if caracteres_actuales <= max_caracteres:\n",
    "            texto_actual += oracion + '.'\n",
    "        else:\n",
    "            textos_divididos.append(texto_actual.strip())\n",
    "            texto_actual = oracion + '.'\n",
    "            caracteres_actuales = len(oracion) + 1\n",
    "\n",
    "    textos_divididos.append(texto_actual.strip())\n",
    "\n",
    "    return textos_divididos\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "sys_prompt = \"\"\"You are a helpful, respectful and honest helper. \n",
    "Always answer in the most helpful way possible using the contextual text provided, do not add information which is not in that context. Your answers should only answer the question once and should not contain any text after the answer.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
    "\n",
    "If the question is not directly related to the provided context, politely inform the user that the question is outside the context scope and cannot be answered accurately.\n",
    "\n",
    "Ensure that your answers are clear and concise, avoiding ambiguity or vague responses.\"\"\"\n",
    "\n",
    "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "\n",
    "Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(pdf):\n",
    "    pdf_reader = PdfReader(pdf)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    # Traducir text a ingles\n",
    "    # max_caracteres = 14000\n",
    "    # textos_divididos = dividir_texto(text, max_caracteres)\n",
    "    # text = \"\"\n",
    "    # for textSec in textos_divididos:\n",
    "    #     text += textSec\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "        )\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    # print(f\"tamano de chunks: {len(chunks)}\")\n",
    "    # for i in range(len(chunks)):\n",
    "    #     print(f\"chunk {i}: {len(chunks[i])}\")\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "    knowledge_base = FAISS.from_texts(chunks, embeddings)\n",
    "    return knowledge_base\n",
    "\n",
    "\n",
    "prompt_template = get_prompt(instruction, sys_prompt)\n",
    "llama_prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": llama_prompt}\n",
    "\n",
    "def modelo_llm(modelo):\n",
    "    return TogetherLLM(\n",
    "        model= modelo,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_chat(query,chain):\n",
    "    #result =chain({\"question\":query, \"chat_history\": history})\n",
    "    user_question_eng = traducir(query)\n",
    "    llm_response = chain.invoke(user_question_eng)\n",
    "    llm_response = traducir_ingles(llm_response['result'], \"spanish\")\n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dante/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/dante/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20913/3817744212.py:18: DeprecationWarning: Call to deprecated function create.\n",
      "  output = together.Complete.create(prompt,\n",
      "/home/dante/.local/lib/python3.10/site-packages/together/legacy/complete.py:23: UserWarning: The use of together.api_key is deprecated and will be removed in the next major release. Please set the TOGETHER_API_KEY environment variable instead.\n",
      "  warnings.warn(API_KEY_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo: togethercomputer/llama-2-7b-chat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El documento trata sobre la creación de un Tribunal Militar Internacional para procesar y castigar a los criminales de guerra, en particular a los responsables de crímenes de lesa humanidad, durante la Segunda Guerra Mundial. El documento describe la composición y funcionamiento del tribunal, así como los crímenes que procesará.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_obj = \"./historia.pdf\"\n",
    "knowledge_base = create_embeddings(pdf_obj)\n",
    "\n",
    "retriever = knowledge_base.as_retriever(search_kwargs={\"k\": 3})\n",
    "modelo = \"togethercomputer/llama-2-7b-chat\"\n",
    "llm = modelo_llm(modelo)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                    chain_type=\"stuff\",\n",
    "                                    retriever=retriever,\n",
    "                                    chain_type_kwargs=chain_type_kwargs)\n",
    "\n",
    "user_question = \"De que trata el documento?\"\n",
    "conversation_chat(user_question, qa_chain )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
