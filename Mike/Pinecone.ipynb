{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SZMik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import together\n",
    "from typing import Any\n",
    "from langchain.llms.base import LLM\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader, PyPDFLoader, TextLoader\n",
    "import os\n",
    "import docx2pdf\n",
    "import pptxtopdf\n",
    "from fpdf import FPDF\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para leer y guardar todos los archivos en PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Txt > PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_pdf(nombre, ubicacion):\n",
    "    \n",
    "    # Crear objeto PDF\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "    # Abrir el archivo de texto\n",
    "    with open(nombre, \"r\", encoding='utf-8') as f:\n",
    "        # Insertar el texto en el PDF usando multi_cell\n",
    "        for x in f:\n",
    "            pdf.multi_cell(0, 10, txt=x)\n",
    "\n",
    "    # Guardar el PDF\n",
    "    pdf.output(ubicacion + \"/\" + os.path.splitext(nombre)[0] + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMG > PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    text = pytesseract.image_to_string(image)\n",
    "    \n",
    "    return text\n",
    "# Extraer texto de la imagen\n",
    "image_path = \"ley_lm.jpg\"\n",
    "output = extract_text_from_image(image_path)\n",
    "print( output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install reportlab\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import os\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "def save_text_to_pdf(text, pdf_path):\n",
    "    c = canvas.Canvas(pdf_path, pagesize=letter)\n",
    "    width, height = letter\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    y = height - 40\n",
    "    for line in lines:\n",
    "        if y < 40:  # If we are near the bottom of the page\n",
    "            c.showPage()\n",
    "            y = height - 40\n",
    "        c.drawString(40, y, line)\n",
    "        y -= 14  # Move to the next line\n",
    "\n",
    "    c.save()\n",
    "\n",
    "# #Ejemplo\n",
    "# image_path = 'agra.jpg'\n",
    "# convert_image_to_pdf(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cualquier otro archivo (menos XLSX) > PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed: 1 files converted successfully, 0 files failed.\n",
      "Conversion completed: 1 files converted successfully, 0 files failed.\n"
     ]
    }
   ],
   "source": [
    "# PONER LA RUTA DE DONDE SE VAN A ***GUARDAR*** LOS ARCHIVOS EN PDF\n",
    "output_folder = \"docs\"\n",
    "\n",
    "\n",
    "# Para guardar el texto de la imagen en un archivo PDF \n",
    "def convert_image_to_pdf(image_path):\n",
    "    text = extract_text_from_image(image_path)\n",
    "    pdf_path = output_folder + '/' + os.path.splitext(image_path)[0] + '.pdf'\n",
    "    save_text_to_pdf(text, pdf_path)\n",
    "    print(f\"Texto almacenadoe en  {pdf_path}\")\n",
    "\n",
    "\n",
    "# PONER LA RUTA DE DONDE SE VAN A ***LEER*** LOS ARCHIVOS ORIGINALES\n",
    "ejemplo_dir = '.'\n",
    "\n",
    "with os.scandir(ejemplo_dir) as ficheros:\n",
    "    for fichero in ficheros:\n",
    "        input_file = fichero.name\n",
    "\n",
    "        if ((fichero.name[-3] == 'o') & (fichero.name[-2] == 'c') & (fichero.name[-1] == 'x')): #docx\n",
    "            docx2pdf.convert(input_file, output_folder)\n",
    "\n",
    "        if ((fichero.name[-3] == 'p') & (fichero.name[-2] == 't') & (fichero.name[-1] == 'x')): #pptx\n",
    "            pptxtopdf.convert(input_file, output_folder)\n",
    "\n",
    "        if ((fichero.name[-3] == 't') & (fichero.name[-2] == 'x') & (fichero.name[-1] == 't')): #txt\n",
    "            txt_to_pdf(input_file, output_folder)\n",
    "\n",
    "        if ((fichero.name[-3] == 'p') & (fichero.name[-2] == 'd') & (fichero.name[-1] == 'f')): #pdf\n",
    "            shutil.copy2(input_file, output_folder)\n",
    "\n",
    "        if ((fichero.name[-3] == 'j') & (fichero.name[-2] == 'p') & (fichero.name[-1] == 'g')): #jpg???\n",
    "            convert_image_to_pdf(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NO TOCAR!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOGETHER_API_KEY\"] = \"f8935229473a0d8a3f4709a9ef32533fe365c0cb215ba8c41413b5ca53a5c767\"\n",
    "\n",
    "class TogetherLLM(LLM):\n",
    "    model: str = \"togethercomputer/llama-2-7b-chat\"\n",
    "    temperature: float = 0.1\n",
    "    max_tokens: int = 1024\n",
    "    together_api_key: str = os.environ.get(\"TOGETHER_API_KEY\")\n",
    "    \n",
    "    class Config:\n",
    "        extra = 'forbid'\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"together\"\n",
    "    def _call(self, prompt: str, **kwargs: Any) -> str:\n",
    "        if not self.together_api_key:\n",
    "            raise ValueError(\"API key is not set.\")\n",
    "        together.api_key = self.together_api_key\n",
    "        output = together.Complete.create(prompt,\n",
    "                                        model=self.model,\n",
    "                                        max_tokens=self.max_tokens,\n",
    "                                        temperature=self.temperature)\n",
    "        print(f\"modelo: {self.model}\")\n",
    "        if 'choices' in output:\n",
    "            return output['choices'][0]['text']\n",
    "        else:\n",
    "            raise KeyError(\"The key 'choices' is not in the response.\")\n",
    "\n",
    "# # Funcion para traduccion a ingles\n",
    "# from googletrans import Translator\n",
    "# import googletrans\n",
    "# translator = Translator()\n",
    "\n",
    "# def traducir(texto_original):\n",
    "#     try :\n",
    "#         origen = translator.detect(texto_original).lang\n",
    "#         # Si el texto esta en otro idioma que no sea ingles lo traduce\n",
    "#         if origen != \"en\":\n",
    "#             #print(f'Traduccion de {origen} a en')\n",
    "#             traduccion = translator.translate(texto_original, dest=\"en\", src=origen).text\n",
    "#             return traduccion\n",
    "#         # En caso contrario devuelve el texto original ya que esta en ingles\n",
    "#         else:\n",
    "#             return texto_original\n",
    "#     except:\n",
    "#         return texto_original\n",
    "    \n",
    "# # Funcion para traduccion a otro idioma\n",
    "# def traducir_ingles(texto_ingles, idioma_destino):\n",
    "#     for abreviatura, nombre_idioma in googletrans.LANGUAGES.items():\n",
    "#         if nombre_idioma == idioma_destino:\n",
    "#             destino = abreviatura\n",
    "#     traduccion = translator.translate(texto_ingles, dest=destino, src=\"en\").text\n",
    "#     return traduccion\n",
    "\n",
    "# def dividir_texto(texto, max_caracteres):\n",
    "#     textos_divididos = []\n",
    "#     texto_actual = ''\n",
    "#     caracteres_actuales = 0\n",
    "\n",
    "#     oraciones = texto.split('.')\n",
    "\n",
    "#     for oracion in oraciones:\n",
    "#         caracteres_actuales += len(oracion) + 1\n",
    "\n",
    "#         if caracteres_actuales <= max_caracteres:\n",
    "#             texto_actual += oracion + '.'\n",
    "#         else:\n",
    "#             textos_divididos.append(texto_actual.strip())\n",
    "#             texto_actual = oracion + '.'\n",
    "#             caracteres_actuales = len(oracion) + 1\n",
    "\n",
    "#     textos_divididos.append(texto_actual.strip())\n",
    "\n",
    "#     return textos_divididos\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "sys_prompt = \"\"\"You are a helpful, respectful, and honest assistant. Always provide the most helpful and accurate answer using only the contextual text provided. Do not add any information that is not in the context.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "1. **Relevance**: Only answer questions based on the provided context. Do not use outside knowledge.\n",
    "2. **Honesty**: If a question does not make sense or is factually incoherent, explain why instead of providing incorrect information.\n",
    "3. **Integrity**: If you don't know the answer based on the context, do not share false information.\n",
    "4. **Scope**: If the question is outside the context, inform the user politely that it cannot be answered accurately.\n",
    "5. **Clarity**: Ensure your answers are clear and concise, avoiding ambiguity or vagueness.\n",
    "6. **Finality**: Answer the question directly and do not include any additional text after the answer.\n",
    "\n",
    "Example of handling an irrelevant question:\n",
    "- \"I'm sorry, but this question is outside the provided context and I cannot answer it accurately.\"\n",
    "\n",
    "Example of handling a nonsensical question:\n",
    "- \"The question seems factually incoherent, so I cannot provide an accurate answer.\"\n",
    "\n",
    "Ensure that your answers are clear and concise, avoiding ambiguity or vague responses.\"\"\"\n",
    "\n",
    "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "prompt_template = get_prompt(instruction, sys_prompt)\n",
    "llama_prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": llama_prompt}\n",
    "\n",
    "def modelo_llm(modelo):\n",
    "    return TogetherLLM(\n",
    "        model= modelo,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamano de documentos: 65\n",
      "tamano de chunks: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SZMik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def load_documents(directory):\n",
    "    # documentPDF = PyPDFDirectoryLoader(directory)\n",
    "    documentPDF = DirectoryLoader(directory, glob='./*.pdf', loader_cls=PyPDFLoader)\n",
    "    # documentPDF = DirectoryLoader('./documents', glob='./*.txt', loader_cls=TextLoader)\n",
    "    documents = documentPDF.load()\n",
    "    return documents\n",
    "\n",
    "def chunk_data(docs, chunk_size=800, overlap=100):\n",
    "    text_spliter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap\n",
    "        )\n",
    "    return text_spliter.split_documents(docs)\n",
    "\n",
    "\n",
    "documents = load_documents('docs')\n",
    "print(f\"tamano de documentos: {len(documents)}\")\n",
    "chunks = chunk_data(documents)\n",
    "print(f\"tamano de chunks: {len(chunks)}\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se desea usar Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone import Pinecone, ServerlessSpec\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# os.environ['PINECONE_API_KEY'] = '57210699-f119-4a04-9224-30521bbd7dc3'\n",
    "\n",
    "# index_name = \"chatify-384\"\n",
    "\n",
    "# pinecone = PineconeVectorStore.from_documents(\n",
    "#     chunks, embeddings, index_name=index_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb\n",
    "\n",
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'db'\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=chunks, \n",
    "                                 embedding=embeddings,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = \"togethercomputer/llama-2-7b-chat\"\n",
    "llm = modelo_llm(modelo)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                    chain_type=\"stuff\",\n",
    "                                    retriever=retriever,\n",
    "                                    return_source_documents=True,\n",
    "                                    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nFuentes:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        # Acceder a la metadata para obtener la página\n",
    "        page_number = source.metadata['page']\n",
    "        print(f\"Fuente: {source.metadata['source']}, Pagina: {page_number}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Que es la SS\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conversation_chat(query,chain):\n",
    "#     #result =chain({\"question\":query, \"chat_history\": history})\n",
    "#     user_question_eng = traducir(query)\n",
    "#     llm_response = chain.invoke(user_question_eng)\n",
    "#     llm_response = traducir_ingles(llm_response['result'], \"spanish\")\n",
    "#     return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_obj = \"./historia.pdf\"\n",
    "# knowledge_base = create_embeddings(pdf_obj)\n",
    "\n",
    "# retriever = knowledge_base.as_retriever(search_kwargs={\"k\": 3})\n",
    "# modelo = \"togethercomputer/llama-2-7b-chat\"\n",
    "# llm = modelo_llm(modelo)\n",
    "# qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "#                                     chain_type=\"stuff\",\n",
    "#                                     retriever=retriever,\n",
    "#                                     chain_type_kwargs=chain_type_kwargs)\n",
    "\n",
    "# user_question = \"De que trata el documento?\"\n",
    "# conversation_chat(user_question, qa_chain )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
